 \documentclass[12pt,a4paper,openany,oneside]{report}
\usepackage[utf8]{vietnam}
\usepackage{amsmath, amsthm, amssymb,amsxtra,latexsym,amscd,graphpap,makeidx}
\usepackage{pgf,tikz}
\usepackage{mathrsfs}
\usetikzlibrary{arrows}
\usepackage{float}
 \usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage{array,tabularx,longtable,multicol,indentfirst,fancyhdr}%
\usepackage[mathscr]{eucal}
\usepackage[top=3.5cm, bottom=3.0cm, left=3.5cm, right=2cm] {geometry}
\usepackage{fancybox}
%==================================  
\newtheorem{dl}{Định lý}[section]
\newtheorem{dn}[dl]{Định nghĩa} 
\newtheorem{bt}[dl]{Bài toán} 
\newtheorem{btp}[dl]{Bài tập} 
\newtheorem{bta}[dl]{Bài} 
\newtheorem{bai}[dl]{Bài}
\newtheorem{tc}[dl]{Tính chất} 
\newtheorem{md}[dl]{Mệnh đề} 
\newtheorem{bd}[dl]{Bổ đề} 
\newtheorem{hq}[dl]{Hệ quả} 
\newtheorem{nx}[dl]{Nhận xét} 
\newtheorem{cy}[dl]{Chú ý} 
\newtheorem{vd}[dl]{Ví dụ} 
\renewcommand{\chaptername}{Chương}
\renewcommand\bibname{Tài liệu tham khảo}
%.....................................

\newcommand{\bpr}{\begin{proof}}
\newcommand{\epr}{\end{proof}}

 

%-----------------------------------------------
\def\en{\enskip}
\def\n{\noindent}
\def\m{\medskip}
\def\en{\enskip}
\def\m{\medskip}
\def\n{\noindent}
\def\Re{\mbox{Re }}
\def\Im{\mbox{Im }}
\def\hcm{\hfill $\square$\\}
\def\imotn{i = 1, 2, \ldots, n}
\def\ii{\item}


\def\N{\mathbb{N}}
\def\Z{\mathbb{Z}}
\def\R{\mathbb{R}}
\def\Q{\mathbb{Q}}
\def\C{\mathscr{C}}  
\def\K{\mathbb{K}}  
\def\F{\mathbb{F}}  
\def\L{\mathbb{L}} 
\DeclareMathOperator{\ord}{ord}

\allowdisplaybreaks
\newenvironment{giai}{\noindent{\em \textit{Giải}. }}{\hfill $\square$}

%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
 
\makeatletter 
\renewcommand{\ps@plain}{
    \renewcommand{\@oddhead}{\hfil{\thepage}\hfil}
    \renewcommand{\@evenhead}{\@oddhead}
    \renewcommand{\@oddfoot}{\empty}
    \renewcommand{\@evenfoot}{\@oddfoot}   }
\makeatother
\pagestyle{fancy}
\fancyhf{}
\rhead{}
\chead{\normalsize  \thepage}
\lhead{\itshape {\nouppercase{}}}
\renewcommand{\headrulewidth}{0pt}


\begin{document}
\pagenumbering{roman}

\newgeometry{top=2.0cm,bottom=3.0cm,left=3.0cm,right=2.8cm}
\setlength{\fboxrule}{1.5pt}
\thisfancypage{\setlength{\fboxsep}{10pt}\setlength{\shadowsize}{0pt}\doublebox}{}

\begin{titlepage}
\fontsize{14pt}{14pt}\selectfont \baselineskip 0.65cm
\thispagestyle{empty}
\begin{center}
{HỌC VIỆN CÔNG NGHỆ BƯU CHÍNH VIỄN THÔNG}\\
\textbf{\MakeUppercase{KHOA CÔNG NGHỆ THÔNG TIN I}}\\
\centerline{--------------------o0o--------------------}  
\end{center}
 

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=6cm]{./logo}
	\end{center}
\end{figure} 
 
 
\vspace{0.5cm}
\begin{center}
\textbf{\MakeUppercase{\Large \bf ĐỒ ÁN TỐT NGHIỆP ĐẠI HỌC}}\\ 
\end{center} 

\vspace{1cm}
\begin{center}
	\textbf{\MakeUppercase{ \bf BAO LỒI XẤP XỈ VÀ ỨNG DỤNG TRONG VIỆC PHÁT HIỆN ĐỊNH HƯỚNG VÀ ĐÓNG GÓI ĐỐI TƯỢNG}}\\ 
\end{center} 
\vspace{2cm}


\begin{tabular}{ll}
	{\textbf{\large{Giảng Viên Hướng Dẫn: }}} & {\textbf{\large{TS. Nguyễn Kiều Linh}}} \\
	{\textbf{\large{Sinh viên thực hiện:}}}  & {\textbf{\large{Trần Xuân Độ}}} \\
	{\textbf{\large{Mã sinh viên: }}}  & {\textbf{\large{B19DCCN183}}} \\
	{\textbf{\large{Lớp:}}}   & {\textbf{\large{D19CNPM04}}}\\
	{\textbf{\large{Niên khóa:}}}   & {\textbf{\large{2019-2023}}}\\
	{\textbf{\large{Hệ đào tạo:}}}   & {\textbf{\large{Đại học chính quy}}}
\end{tabular}


\vfill
\begin{center}
{{\bf Hà Nội, 12/2023}}
\end{center}
\end{titlepage}

\newgeometry{top=2.0cm,bottom=3.0cm,left=3.0cm,right=2.8cm}
\setlength{\fboxrule}{1.5pt}
\thisfancypage{\setlength{\fboxsep}{10pt}\setlength{\shadowsize}{0pt}\doublebox}{}

\fontsize{14pt}{14pt}\selectfont \baselineskip 0.65cm
\thispagestyle{empty}
\begin{center}
	{HỌC VIỆN CÔNG NGHỆ BƯU CHÍNH VIỄN THÔNG}\\
	\textbf{\MakeUppercase{KHOA CÔNG NGHỆ THÔNG TIN I}}\\
	\centerline{--------------------o0o--------------------}  
\end{center}


\begin{figure}[H]
	\begin{center}
		\includegraphics[width=6cm]{./logo}
	\end{center}
\end{figure} 



\vspace{0.5cm}
\begin{center}
	\textbf{\MakeUppercase{\Large \bf ĐỒ ÁN TỐT NGHIỆP ĐẠI HỌC}}\\ 
\end{center} 

\vspace{1cm}
\begin{center}
	\textbf{\MakeUppercase{ \bf Bao lồi xấp xỉ và ứng trong việc phát hiện định hướng và đóng gói đối tượng.}}\\ 
\end{center} 
\vspace{2cm}


\begin{tabular}{ll}
	{\textbf{\large{Giảng Viên Hướng Dẫn: }}} & {\large TS. Nguyễn Kiều Linh}\\
	{\textbf{\large{Sinh viên thực hiện:}}}  & {\large Trần Xuân Độ} \\
	{\textbf{\large{Mã sinh viên: }}}  & {\large B19DCCN183} \\
	{\textbf{\large{Lớp:}}}   & {\large D19CNPM04}\\
	{\textbf{\large{Niên khóa:}}}   & {\large 2019-2023}\\
	{\textbf{\large{Hệ đào tạo:}}}   & {\large Đại học chính quy}
\end{tabular}


\vfill
\begin{center}
	{{\bf Hà Nội, 12/2023}}
\end{center}

%%%%%%%%%%%%%%%

\newpage
\restoregeometry
 \pagestyle{fancy}
\pagenumbering{roman}
 \fontsize{13pt}{13pt}\selectfont \baselineskip 0.75cm 

\tableofcontents

%%%%%%%%%%%%%%%%%%%
\newpage
\begin{center}
	\Large{\textbf{LỜI CẢM ƠN}}\\
\end{center}
\vspace{1cm}
Đây là mục tùy chọn

...........................
\
 \\
 
 \
  \\
 \
  \\
 
\phantom{nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn}\  {\textit{Hà Nội, tháng ....  năm 20....}} \\
\phantom{nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn} {Sinh viên}\\
\phantom{nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn} \\
\phantom{nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn} \\ 
\phantom{nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn} \\ 
\phantom{nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn}   {Nguyễn Văn A}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\newpage 
\addcontentsline{toc}{chapter}{\bf  Danh sách hình vẽ} 

\listoffigures

%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage 
\addcontentsline{toc}{chapter}{\bf  Danh sách bảng} 
\listoftables

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\newpage
{\addcontentsline{toc}{chapter}{Danh sách các ký hiệu và chữ viết tắt}}

\begin{center}
	{\LARGE
		{\bf Danh mục các ký hiệu và chữ viết tắt}}
\end{center}
\vspace{1.25cm}
{\fontsize{13}{13}\selectfont
	\begin{tabular}{ll}
		conv$(D)$ & bao lồi của tập hợp $D$\\
		$\partial ({\rm conv}(D))$ & biên của bao lồi conv$(D)$\\
		CH($D$) & tập các hình tròn cực biên của tập $D$\\
		$V_C$ & tập đỉnh của bao lồi conv($C$)\\
		$[p,q]$ & đoạn thẳng nối $p$ với $q$\\
		$pq$& đường thẳng đi qua $p$ và $q$\\
  .......... & ..................
	\end{tabular}
}


 
\newpage
\pagenumbering{arabic} 
\pagestyle{fancy} 

\chapter*{Mở đầu}
\addcontentsline{toc}{chapter}{\vspace*{-8pt}  Mở đầu} 

Trong nhiều thập kỷ, chúng ta đã chứng kiến quá trình phát triển đáng kể của bài toán nhận diện đối tượng trong ảnh. Đóng góp vào sự phát triển này chính là việc sử dụng mạng học sâu kết hợp với đa dạng các cách biểu diễn đặc trưng, các cơ sở dữ liệu huấn luyện có kích thước lớn, và việc đào tạo trước các mô hình để tiết kiệm thời gian và chi phí. Tuy nhiên, phần lớn các bộ phát hiện đối tượng đều gặp phải vấn đề khi biểu diễn các đối tượng từ trên cao nhìn xuống, có hướng bất kỳ, hoặc các đối tượng có bố cục không giống nhau trong quá trình đào tạo. Vấn đề trở nên nghiêm trọng hơn đối với các đối tượng phân bố dày dặc, gây ra hiện tượng răng cưa ở các vùng giao nhau của trường tiếp nhận (reception field).


Một trong những giải pháp được sử dụng để phát hiện đối tượng có hướng, đó là sử dụng phương pháp làm giàu đặc trưng (feature augmentation)/mỏ neo (anchor), cung cấp nhiều các đặc trưng hơn để huấn luyện các bộ phát hiện. Các giải pháp này tuy nhiên lại gây ra sự phức tạp trong tính toán, từ đó dẫn đến nhiều sai sót. Một giải pháp khác đó là định nghĩa bộ biến đổi RoI (RoIs transformer), áp dụng phép phép biến đổi không gian RoIs, cùng lúc đó học các tham số dưới sự giám sát của hộp bao có hướng. Những bộ biến đổi này được cho là linh hoạt, nhạy bén, hoạt động mượt, cho phép trường tiếp nhận thích nghi với các đối tượng có hướng. Tuy nhiên, vấn đề về điều chỉnh lưới đặc trưng cho đối tượng có bố cục khác nhau vẫn chưa được giải quyết. Đây chính là nguyên nhân gây ra hiện tượng đặc trưng răng cưa (feature aliasing), xảy ra khi các đối tượng nằm phân bổ dày đặc trong khung hình.


Bởi các lý do trên, ta sử dụng một cách tiếp cận khác: sử dụng phương pháp điều chỉnh đặc trưng bằng bao lồi (convex-hull) dành cho các đối tượng có hướng và phân bố dày đặc. Mục tiêu của phương pháp là để điều chỉnh các đặc trưng nằm trong lưới tích chập thông thường với các đối tượng có bố cục phân bố không đều. Ta mô hình hóa bố cục của đối tượng giống như một bao lồi, điều này thuận lợi hơn so với sử dụng bố cục hình chữ nhật, đáp ứng được yêu cầu bao phủ toàn bộ đối tượng nhưng giảm thiểu tối đa diện tích nền được bao. Mỗi bao lồi là tập hợp các điểm đặc trưng (feature points) xác định đường biên của đối tượng, sử dụng chỉ số giao của bao lồi trên hợp của bao lồi (Convex Intersection over Union) để xác định vị trí đối tượng. Bên trong bao lồi, các đặc trưng phân biệt mô tả sự xuất hiện của đối tượng để thực hiện phân lớp chính xác.


Mục tiêu của đồ án này là tìm hiểu, nghiên cứu phương pháp phát hiện đối tượng dày đặc có hướng, cụ thể là nghiên cứu phương pháp BeyoundBoundingBox dành cho bài toán phát hiện đối tượng. Ngoài ra, đồ án còn tìm hiểu thuật toán phát hiện bao lồi mới, thay thế vào thuật toán tìm bao lồi cũ của bộ phát hiện, thực hiện huấn luyện lại mô hình, kiểm nghiệm và đo lường độ hiệu quả của thuật toán mới so với thuật toán cũ.


Trong đồ án em sẽ tập trung trình bày một số nội dung chính như sau:

\textbf{Chương 1: Giới thiệu bài toán phát hiện, định hướng và đóng gói đối tượng:}
Khái quát các vấn đề và phương pháp nhận dạng đối tượng, trình bày về các phương pháp liên quan, nguyên lý và cách thức triển khai, giới thiệu sử dụng thuật toán bao lồi xấp xỉ để thực hiện bài toán.


\textbf{Chương 2: Trình bày thuật toán bao lồi xấp xỉ:}
Giới thiệu về thuật toán bao lồi xấp xỉ, lý thuyết và triển khai thuật toán bằng mã C++.


\textbf{Chương 3: Thực nghiệm và kết quả:}
 Trình bày cách thức thay thế thuật toán, các bước để tạo cơ sở dữ liệu huấn luyện, phân chia ảnh, tạo môi trường huấn luyện cũng như các bước để huấn luyện mô hình. Ngoài ra phần này sẽ trình bày một số kết quả thu được, so sánh với số liệu của thuật toán cũ.


\textbf{Chương 4: Tổng kết:}
Tổng kết bài toán, tóm tắt những kết quả đã đạt được và còn chưa đạt được. Từ đó đề xuất mục tiêu hướng tới cũng như hướng nghiên cứu, phát triển tiếp theo.

\chapter{Giới thiệu bài toán phát hiện, định hướng và đóng gói đối tượng}

\section{Giới thiệu}
Biểu đồ luồng của phương pháp CFA được cung cấp ở hình \ref{work_flow_cfa}, sử dụng phương pháp RepPoint làm cơ sở xây dựng. Là một bộ phát hiện không dùng mỏ neo (anchor-free detector), CFA bao gồm 2 giai đoạn: giai đoạn sinh bao lồi (convex-hull adaptation) và giai đoạn thích ứng bao lồi (convex-hull adaptation). Giai đoạn đầu tiên dự đoán bao lồi cho tất cả các vị trí trên các bản đồ đặc trưng và ước lượng bố cục của bao lồi. Giai đoạn 2 tinh chỉnh lại các bao lồi đã dự đoán cũng như làm chúng thích ứng với các đối tượng dày đặc. Trong quá trình suy luận, chỉ bước sinh bao lồi (convex-hull generation)được thực hiện để định vị đối tượng mà không cần xây dựng tập các bao lồi (convex-hull set construction), đảm bảo sự đơn giản và hiệu quả của bộ phát hiện. Với mỗi bao lồi dự đoán, bộ phát hiện tính toán một hình chữ nhật bao nhỏ nhất và hợp nhất những hình chữ nhật chồng chéo sử dụng bộ phát hiện Non-Maximum Supression(NMS) để thực hiện đánh giá. Đoạn tiếp dưới đây sẽ phân tích sự bất lơi của việc biểu diễn bằng hộp và trình bày cách biểu diễn bằng bao lồi, sau đó giới thiệu các mô đun sinh bao lồi và mô đun thích ứng bao lồi.
Xem xét rằng lưới đặc trưng CNN được căn chỉnh theo trục tọa độ, các bộ phát hiện hiện đại điển hình thường sử dụng hộp (boxes), ví dụ: hộp hình chữ nhật hoặc hộp xoay hình chữ nhật, để bao phủ toàn bộ một đối tượng. Các bộ phát hiện không sử dụng mỏ neo hiện nay, như RepPoint và ExtremePoint, cho phép làm biến dạng lưới đặc trưng, nghĩa là sắp xếp các điểm đặc trưng sao cho phù hợp với hộp bao đối tượng. Tuy nhiên, chúng không xem xét việc thích ứng với các đối tượng có bố cục không phải là hình chữ nhật, những đối tượng này sẽ gây nên hiện tượng đặc trưng răng cưa khi có nhiều đối tượng nằm sát nhau. Các bài nghiên cứu gần đây như DRN và R3Det đã xử lý vấn đề này bằng cách dự đoán hướng của đối tượng, nhưng cũng không thích ứng tốt các đặc trưng cho các đối tượng. Nhược điểm của các phương pháp đang tồn tại, đó chính là sử dụng hộp bao hình chữ nhật lên các đối tượng có bố cục bất thường, điều này làm giảm đi khả năng biểu diễn của các đặc trưng trong tích chập.
\begin{figure}[ht!]
	\begin{center}
		\includegraphics[width=400px]{./compare_cfa_with_other.JPG}
		\caption{Minh hoạ vấn đề. (Bên trên) Khi sử dụng cách biểu diễn dạng hộp, các đối tượng có hướng phân bố dày đặc gây ra hiện tượng đặc trưng răng cưa tại các vùng giao của trường tiếp nhận giữa các đối tượng. (Bên dưới) Với cách biểu diễn bao lồi, phương pháp CFA xử lý tốt các đặc trưng nằm trên lưới tích chập thông thường của các đối tượng có hướng phân bố không đều, giải quyết hiện tượng răng cưa đặc trưng hiệu quả}
		\label{fig_dhandang1}
	\end{center}
\end{figure} 


\begin{figure}[ht!]
	\begin{center}
		\includegraphics[width=450px]{./work_flow_cfa.JPG}
		\caption{Biểu đồ luồng quy trình thực hiện của bộ phát hiện CFA.}
		\label{work_flow_cfa}
	\end{center}
\end{figure} 

\section{Xây dựng tập bao lồi đầu tiên}
Việc biểu diễn bằng khung hình chữ nhật do bao lồi sinh ra làm giảm khả năng biểu diễn đối tượng. Vì thế phương pháp CFA đã đề xuất biểu diễn phạm vi của đối tượng bằng bao lồi. Mỗi bao lồi là một tập hợp các điểm thoả mãn công thức:

\begin{align} \label{convex_hull_definition}
		C_i=\left\{\left(x_i^k, y_i^k\right)\right\}_i^{k=1 \ldots K}
\end{align}
Trong đó: $C_i$ là bao lồi thứ i, $\left(x_i^k, y_i^k\right)$ là điểm nằm trên bao lồi thứ k, k là chỉ số của điểm đặc trưng, $K = 9$ tương ứng với 9 điểm được khởi tạo của bao lồi.

\begin{figure}[ht!]
	\begin{center}
		\includegraphics[width=445px]{./compare_convex-hull_with_rectangle.jpg}
		\caption{So sánh biểu diễn hộp có hướng (bên trên) so với biểu diễn bao lồi (ở dưới).}
	\end{center}
\end{figure} 


Việc huấn luyện có thể xem như là quá trình dự đoán độ lệch (offset), trong khi hệ số CIoU cần được tối đa hoá để đạt được so khớp tối ưu nhất. Đây là phương pháp sử dụng phép toán tích chập để dự đoán độ lệch:
$\left(\Delta x_i^k, \Delta y_i^k\right)$
với từng điểm đặc trưng, sau trả về một bản đồ độ bù cho các đặc trưng
$O \in R^{H \times W \times W}$ ($H, W, C$ lần lượt tương ứng với chiều dài, chiều rộng và số lượng kênh của bản đồ đặc trưng):
\begin{align} \label{convex_hull_learn_offset}
	\hat{\mathcal{C}}_i(\theta) \leftarrow\left\{\left(x_i^k+\Delta x_i^k(\theta), y_i^k+\Delta y_i^k(\theta)\right)\right\}_i^{k=1 \ldots K}
\end{align}

Trong đó: $\theta$ biểu thị là các tham số của mạng. Việc dự đoán offset sẽ thực hiện theo công thức trên.

\section{Tích chập biến dạng}
Tích chập biến dạng (Deformable convolution) là dạng tích chập mà vị trí thực hiện tích chập bị biến dạng, không giống tích chập truyền thống là dạng lưới $N\mathrm{x}N$. Ưu điểm của phương pháp này giúp trích xuất các đặc trưng mong muốn được chính xác hơn, lấy mẫu được ở những vị trí đa dạng hơn (Phép tích chập truyền thống chỉ có thể trích xuất các đặc trưng trên một khung hinh chữ nhật).(Hình \ref{so_sanh_tich_chap_thong_thuong_deformable})

\begin{figure}[ht!]
	\begin{center}
		\includegraphics[width=445px]{./compare_normal_with_deformable_convolution.jpg}
		\caption{So sánh tích chập thông thường và tích chập biến dạng.}
		\label{so_sanh_tich_chap_thong_thuong_deformable}
	\end{center}
\end{figure} 

Phép tích chập biến dạng thực ra là thêm phần bù cho các điểm tích chập lấy mẫu. (Hình \ref{offset_deformable_convolution})

\begin{figure}[ht!]
	\begin{center}
		\includegraphics[width=445px]{./feature_offset_type.jpg}
		\caption{a) lấy mẫu tích chập với 9 điểm lấy mẫu. b) để có tích chập biến dạng, thêm độ dịch chuyển vào mỗi điểm lấy mẫu (mũi tên xanh). c) phép biến đổi tỷ lệ. d) phép quay
		}
		\label{offset_deformable_convolution}
	\end{center}
\end{figure} 

\begin{figure}[ht!]
	\begin{center}
		\includegraphics[width=400px]{./deformable_process.jpg}
		\caption{Quá trình thực hiện tích chập biến dạng.}
		\label{deformable_process}
	\end{center}
\end{figure} 


Cho đầu vào là một bản đồ đặc trưng, giả sử phép tích chập là 3x3. Để học được phần bù, định nghĩa một lớp tích chập 3x3 khác, chiều của đầu ra là kích thước của bản đồ đặc trưng ban đầu, số kênh = $2N$. (Hình \ref{deformable_process}) Tiếp theo thực hiện tích chập biến dạng, dựa trên độ bù của các phần đã được tính trước đó, sau đó thực hiện phép tích chập như thông thường.
\section{Thuật toán Jarvis March}
Sau khi học được phần bù, việc hoàn thành cập nhật các điểm đặc trưng của bao lồi được thực hiện bởi thuật toán Jarvis March, bao lồi nhỏ nhất phù hợp với điều kiện sẽ được tạo ra sau mỗi vòng lặp.

\begin{figure}[ht!]
	\begin{center}
		\includegraphics[width=435px]{./jarvis_march_steps.jpg}
		\caption{mô tả các bước thực hiện thuật toán Jarvis March}
		\label{fig_dhandang1}
	\end{center}
\end{figure} 
Tóm tắt các bước thực hiện thuật toán Jarvis March:

\begin{itemize}
	\item Bước 1: Chọn điểm xuất phát là v1 nằm trên đường biên. Tìm điểm v2 tiếp theo sao cho mọi điểm khác trong tập hợp nằm ở phía bên trái đoạn thằng nối v1 và v2.
	\item Bước 2: Tìm điểm v3 tiếp theo trong tập các điểm còn lại, sao cho v1, v2, v3 thỏa mãn góc ngược chiều kim đồng hồ (Counter Clock Wise - CCW). Điền này có nghĩa là v3 nằm ở bên trái đoạn thẳng nối v1 và v2. Nếu điều kiện này được đáp ứng, tức là v3 là 1 điểm nằm ở ngoại vi hơn.
	\item Bước 3: Nếu điều kiện bước trên thỏa mãn, ghi đè giá trị của v3 lên v2. Gán giá trị của v3 cho v2, tức v2 = v3. Quay lại bước 2 để tìm điểm ngoại vi tiếp theo.
	\item Bước 4: Lặp lại bước 3 cho đến khi tất cả các điểm đã được duyệt qua, tức là tìm thấy điểm ngoại vi tiếp theo được tìm thấy. Quá trình này tạo ra một chuỗi các điểm trên đường biên của bao lồi.
	\item Bước 5: Ghi đè giá trị của v2 lên v1. Sau khi tìm thấy điểm ngoại vi tiếp theo, gán giá trị của v2 lên v1, tức v1 = v2.
	\item  Bước 6: Lặp lại bước 2 cho đến khi điểm tiếp theo trả về chính là điểm xuất phát. Quá trình này sẽ tiếp tục cho đến khi ta quay trở lại điểm xuất phát ban đầu, hoàn thành toàn bộ quá trình tìm bao lồi.
\end{itemize}

\section{Đinh nghĩa công thức Convex Intersection over Union (CIoU)}
Dựa vào mỗi bao lồi dự đoán, có thể tính toán được hàm mất mát vị trí và phân lớp của một đối tượng. Công thức CIoU giữa bao lồi dự đoán thứ $i$:  $C_i(\theta)$ và hộp bao thật sự $\mathcal{B}_j$ của đối tượng thứ $j$ được tính như sau:

\begin{align} \label{CioU_fomular}
	\operatorname{CIoU}\left(\mathcal{C}_i(\theta), \mathcal{B}_j\right)=\frac{\left|\mathcal{C}_i(\theta) \cap \mathcal{B}_j\right|}{\left|\mathcal{C}_i(\theta) \cup \mathcal{B}_j\right|}-\frac{\left|\mathcal{R}_j \backslash\left(\mathcal{C}_i(\theta) \cup \mathcal{B}_j\right)\right|}{\left|\mathcal{R}_j\right|}
\end{align}
Trong đó: $\mathcal{R}_j$ là hợp của hai đa giác, tức là đa giác nhỏ nhất có thể bao quanh  $C_i(\theta)$ và $\mathcal{B}_j$.
\section{Hàm mất mát}
Theo công thức \ref{CioU_fomular}, hàm mất mát vị trí CIoU được định nghĩa là:
\begin{align} \label{cong_thuc_ham_loss_CIoU}
	\mathcal{L}_i^{l o c}(\theta)=1-\operatorname{CIoU}\left(\mathcal{C}_i(\theta), \mathcal{B}_j\right)
\end{align}
Cho $f_i^{k}(\theta)$ là đặc trưng của điểm thứ $k$, bao lồi đặc trưng $f_i(\theta)$ được tính bởi tổng có trọng số của tất cả các điểm đặc trưng trên bao lồi dự đoán $\mathcal{C}_i(\theta)$, tức là bằng công thức: $f_i(\theta) = \sum_{k}m w_i^k.f_i^k(\theta)$, trong đó, $w_i^k$ biểu thị các trọng số đặc trưng có thể học được từ tích chập biến dạng (DCN). Dựa vào bao lồi đặc trưng, điểm dự đoán $S_i(\theta)$ của bao lồi dự đoán $C_i(\theta)$ được tính bởi phép tích chập, hàm mất mát phân loại của bao lồi dự đoán $C_i(\theta)$ tương ứng với $B_j$ được định nghĩa là:
\begin{align} \label{loss_classification}
	\mathcal{L}_i^{c l s}(\theta)=\mathrm{FL}\left(S_i(\theta), Y_j\right)
\end{align}
ở đây $Y_j$ biểu thị là nhãn nhị phân thật sự (ground-truth) và FL() ở đây là hàm mất mát Focal (Focal loss). Kết quả có được là hàm mất mát dành cho bao lồi dương: 
\begin{align} \label{loss_function_positive_convex}
	\mathcal{L}_i^{+}(\theta)=\mathcal{L}_i^{c l s}\left(\mathcal{S}_i(\theta), Y_j\right)+\lambda \mathcal{L}_i^{l o c}\left(\mathcal{C}_i(\theta), \mathcal{B}_j\right)
\end{align}
Hàm mất mát \ref{loss_function_positive_convex} là tổng của hàm mất mát vị trí \ref{cong_thuc_ham_loss_CIoU} và hàm mất mát phân loại \ref{loss_classification}.
Hàm mất mát dành cho bao lồi âm là:

\begin{align} \label{loss_negative_convex}
	\mathcal{L}_i^{-}(\theta)=\mathcal{L}_i^{c l s}\left(\mathcal{S}_i(\theta), Y_j\right)
\end{align}
Ngoài ra, trong quá trình huấn luyện (Hình \ref{work_flow_cfa}), vì các bao lồi được ban đầu chỉ được sinh ra bằng cách tối ưu CIoU, một hàm loss cần được định nghĩa cho việc giám sát:
\begin{align} \label{loss_det_1}
	\mathcal{L}^{\operatorname{det} 1}(\theta)=\frac{1}{J} \sum_i \mathbb{I}_{\left(x_i, y_i\right)} \mathcal{L}_i^{l o c}(\theta)
\end{align}
Nhìn chung, trong giai đoạn đầu tiên của việc sinh bao lồi, hàm mất mát $L^{\operatorname{det} 1}$ bên trên là hàm cần được quan tâm. Trong giai đoạn 2, hai hàm mất mát phân lớp (\ref{loss_negative_convex} và \ref{loss_function_positive_convex}) sẽ được sử dụng để phân loại bao lồi
\section{Thích ứng bao lồi}
Phương pháp biểu diễn bằng bao lồi giúp định vị đối tượng ở bất kỳ hình dạng nào, tuy nhiên vẫn có một vấn đề, làm thế nào để định vị một cách chính xác các đối tượng dày đặc, đặc biệt là các đối tượng có đặc trưng răng cưa. Vì vậy bộ phát hiện CFA đã đề xuất một phương pháp thích ứng mới để tinh chỉnh các bao lồi sinh ra ở giai đoạn 1 để đạt được vị trí chính xác hơn và phân lớp hiệu quả hơn.
\subsection{Xây dựng tập các bao lồi}
Bộ phát hiện cho xây dựng một tập các bao lồi với mỗi đối tượng, để một đối tượng mục tiêu có thể khớp với nhiều bao lồi phù hợp để cùng nhau tối ưu các đặc trưng của các đối tượng dày đặc.

\begin{figure}[ht!]
	\begin{center}
		\includegraphics[width=445px]{./construction_convex_hull_set.jpg}
		\caption{xây dựng tập các bao lồi để biểu diễn các đối tượng, đặc biệt với những đối tượng phân bổ dày đặc}
		\label{fig_dhandang1}
	\end{center}
\end{figure} 
Với mỗi mục tiêu, ý tưởng xây dựng tập bao lồi tương ứng là: theo như hệ số CIoU giữa bao lồi dự đoán và bao lồi thực tế, chọn I bao lồi đứng đầu là ứng cử viên cho bao lồi dương để xây dựng tập các bao lồi. Ngoài ra cũng có thể xây dựng tập bao lồi sử dụng ngưỡng CIoU xác định bằng thực nghiệm. Các bao lồi còn lại không thuộc vào bất kỳ tập bao lồi nào sẽ được gộp lại thành tập bao lồi âm $S$.
\begin{align} \label{construct_convex_hull_set}
\mathcal{L}_{S_j}^{+}(\theta)=\frac{1}{\left|S_j\right|} \sum_{i \in S_j} \omega_i \mathcal{L}_i^{+}(\theta)
\end{align}
Khi nhiều đối tượng tập hợp lại cùng nhau, không phải tất cả các bao lồi nằm trong tập bao lồi đều phù hợp với đối tượng, và các bao lồi có đặc trưng răng cưa sẽ phải được phân loại thành tập các bao lồi âm. Cùng thời điểm đó, các bao lồi được chia sẻ bởi nhiều đối tượng phải phải có độ tin cậy thấp hơn.
\subsection{Chiến lược phân đoạn tập các bao lồi}
Để giải quyết vấn đề đặc trưng răng cưa ở các đối tượng dày đặc, bộ phát hiện CFA đề xuất chiến lược phân đoạn tập các bao lồi để đánh giá động các mẫu bao lồi âm và mẫu dương, chuyển đổi trọng số $\omega_i$ thành $f\left(L_i^{+}(\theta)\right)$. Sau khi thay thế, được công thức sau:
\begin{align} \label{loss_positive_convert}
	\mathcal{L}_{s_j}^{+}(\theta)=\frac{1}{\left|S_j\right|} \sum_{i \in S_j} f\left(\mathcal{L}_i^{+}(\theta)\right) \mathcal{L}_i^{+}(\theta)
\end{align}
Trong đó: $f$ là hàm lỗi đơn điệu giảm phân phối Gaussian: $f\left(x\right) = 1.0 - \frac{2}{\sqrt{\pi}}\int_0^xe^{-t^2}$, có nghĩa là giá trị mất càng nhỏ, độ tin cậy càng cao.

\begin{figure}[ht!]
	\begin{center}
		\includegraphics[width=445px]{./gaussian_gradient.jpg}
		\caption{Phân chia tập bao lồi theo hướng dẫn của nguyên tắc nhất quán độ dốc.}
		\label{gradient_consistentcy_illustration}
	\end{center}
\end{figure} 
Nguyên tắc phân chia tập bao lồi là nguyên tắc nhất quá độ dốc. Bằng cách lấy đạo hàm của công thức công thức \ref{loss_positive_convert}, ta có được:
\begin{align} \label{gradient_of_loss}
	 \frac{\partial \mathcal{L}_{s_j}^{+}(\theta)}{\partial \theta}=\frac{1}{\left|S_j\right|} \sum_{i \in S_j} \frac{\partial\left(f\left(\mathcal{L}_i^{+}(\theta)\right) \mathcal{L}_i^{+}(\theta)\right)}{\partial \mathcal{L}_i^{+}(\theta)} \frac{\partial \mathcal{L}_i^{+}(\theta)}{\partial \theta}
\end{align}
Tiêu chí để thực hiện phân đoạn tập các bao lồi là: đạo hàm của mỗi một bao lồi dương $\frac{\partial L_i^{+}(\theta)}{\partial \theta}$ yêu cầu đạo hàm của toàn bộ tập bao lồi $\frac{\partial L_{S_j}^{+}(\theta)}{\partial \theta}$ là nhất quán. Điều này có nghĩa là: bao lồi nào có độ dốc không nhất quán được xem là bao lồi âm, tức là những bao lồi này sẽ dẫn đến hiện tượng răng cưa đặc trưng. Xem xét công thức \ref{gradient_of_loss}, nếu $\frac{\partial\left(f\left(L_i^{+}(\theta)\right) L_i^{+}(\theta)\right)}{\partial L_i^{+}(\theta)}$ mang giá trị dương, thì bao lồi $C_i$ được xếp là bao lồi dương, hoặc ngược lại bao lồi sẽ là âm. Xem xét hình \ref{gradient_consistentcy_illustration}, khi sắp xếp các giá trị mất mát  $\frac{\partial L_i^{+}(\theta)}{\partial \theta}$ theo thứ tự tăng dần, $f\left(\partial L_i^{+}(\theta)\right) L_i^{+}(\theta)$ (đường màu cam) là một hàm lồi hướng lên với một cực trị duy nhất, trong khi đường  $\frac{\partial\left(f\left(L_i^{+}(\theta)\right) L_i^{+}(\theta)\right)}{\partial L_i^{+}(\theta)}$ (màu xanh lục) chia các bao lồi thành tập các bao lồi dương $S_j$ và tập bao lồi âm $S\_$.

Cùng thời điểm đó, để xử lý đặc trưng răng cưa, tác giả cũng giới thiệu hệ số chống đặc trưng răng cưa:
\begin{align}\label{FAA_fomular}
	p_i = \gamma\dot{\frac{\mathrm{CIoU}(\mathcal{C}_i, \mathcal{B}_j)}{\sum_{m=1}^{M}\mathrm{CIoU}\left(\mathcal{C}_i, \mathcal{B}_j\right)}}
\end{align}
Hệ số này thể hiện mức độ mà một đối tượng thuộc về một đối tượng duy nhất, khi nó chồng lên M đối tượng khác. $\gamma$ là hệ số chống đặc trưng răng cưa.
Hàm mất mát được cập nhật thành: 

\begin{align}\label{loss_update}
	\mathcal{L}_{s_j}^{+}(\theta)=\frac{1}{\left|S_j\right|} \sum_{i \in S_j} p_i f\left(\mathcal{L}_i^{+}(\theta)\right) \mathcal{L}_i^{+}(\theta)
\end{align}
Giai đoạn 2 của quá trình tối ưu được điều khiển bởi hàm mất mát trên tập bao lồi, hàm này được xác định bằng cách kết hợp hàm mất mát phân loại và hàm mất mát vị trí:
\begin{align} \label{loss_det_2}
	\begin{aligned}
		\mathcal{L}^{\operatorname{det} 2}(\theta)= & \frac{1}{J} \sum_{j=1}^J \frac{1}{\left|S_j\right|} \sum_{i \in S_j} p_i f\left(\mathcal{L}_i^{+}(\theta)\right) \mathcal{L}_i^{+}(\theta) \\
		& +\frac{1}{\left|S_{-}\right|} \sum_{i \in S_{-}} \mathcal{L}_i^{-}(\theta)
	\end{aligned}
\end{align}

Hàm mất mát này xem xét sự tương ứng về đặc trưng của nhiều đối tượng, tiến hành phạt các bao lồi được chia sẻ bởi nhiều đối tượng, và giảm thiểu đặc trưng răng cưa để đạt được thích ứng đặc trưng tối ưu. Cuối cùng hàm mất mát của toàn bộ bộ phát hiện CFA là: 
\begin{align} \label{final_loss_CFA}
	L^{\operatorname{det} 1}(\theta)+L^{\operatorname{det} 2}(\theta)
\end{align}

\chapter{Thuật toán tính bao lồi xấp xỉ}
\textit{giới thiệu chung về thuật toán, cách dùng, có bao nhiêu loại thuật toán}
\section{Outer convex approximation}
Cho:
\begin{align} \label{ct2.1} 
	X:=\left\{x_1, x_2, \ldots, x_n\right\} \subset \mathbb{R}^2
\end{align}
Giả sử không mất tính tổng quát rằng
\begin{align} \label{ct2.2} 
	x_1, x_2, \ldots, x_n  \text{ không cùng nằm trên cùng một đường thẳng.}
\end{align}
Ta viết tất cả các vector thành dạng vector hàng, những vector này sẽ có chuyển vị của chúng được ký hiệu bởi chỉ số trên $T$, và sử dụng chỉ số trên để chỉ định các thành phần của chúng, ví dụ: $x = \left(x^1, x^2\right)\in\mathbb{R}^2$. Cho $x, x'\in\mathbb{R}^2$, chứng tỏ:
\begin{equation}\label{ct2.3}
	\begin{aligned}
		& {\left[x, x^{\prime}\right]:=\left\{(1-\lambda) x+\lambda x^{\prime} \mid \lambda \in[0,1]\right\}} \\
		& \left(x, x^{\prime}\right):=\left\{(1-\lambda) x+\lambda x^{\prime} \mid \lambda \in(0,1)\right\}
	\end{aligned}
\end{equation}

Cho $X$ thỏa mãn (\ref{ct2.1}) - (\ref{ct2.2}) và $\delta \geq 0$, trong phần này em muốn tìm một bao lồi xấp xỉ của $X$, nghĩa là:
\begin{align}\label{ct2.4}
	\text{một đa giác lồi }\mathcal{P}^{outer} \text{thỏa mãn bao lồi }X\subset\mathcal{P}^{outer}
\end{align}
sao cho
\begin{align}\label{ct2.5}
	dist_H\left(conv\ X, \mathcal{P}^{outer}\right) \leq \delta
\end{align}
$P^{outer}$ đươc xác định bởi:
\begin{align}\label{ct2.6}
	P^{outer} := \{x\in\mathbb{R}^2 | dx^T \leq \beta_d\ \text{ với tất cả d} \in D\}
\end{align}
trong đó $D \subset \mathbb{R^2}$ biểu thị tập các hướng tối đa và $\beta_d \in \mathbb{R}$ biểu thị ngưỡng tương ứng với hướng $d \in D$. Với D cho trước, $\mathcal{P}^{outer}$ là bao lồi xấp xỉ phù hợp nhất chứa $X$ nếu:
\begin{equation}\label{ct2.7}
	\beta_d:=\max _{x \in X} d x^T \text{với tất cả d }\in D
\end{equation}
Cho P là tập các đỉnh của $\mathcal{P}^{outer}$.
Ta bắt đầu quá trình xác định bao lồi xấp xỉ ngoài với hình chữ nhật nhỏ nhất có chứa $X$, tập $X$ này có chứa cạnh song song với trục tọa độ. Theo công thức (\ref{ct2.5}) - (\ref{ct2.6}), hình chữ nhật $\mathcal{P}^{outer}$ được xác định bởi:
\begin{align}\label{ct2.8}
	D:=\{(1, 0), (0, 1), (-1, 0), (0, -1)\}
\end{align}
và:
\begin{equation}
	\begin{aligned}
		& \beta_{(1,0)}:=\max \left\{x^1 \mid\left(x^1, x^2\right) \in X\right\}, \\
		& \beta_{(0,1)}:=\max \left\{x^2 \mid\left(x^1, x^2\right) \in X\right\}, \\
		& \beta_{(-1,0)}:=\max \left\{-x^1 \mid\left(x^1, x^2\right) \in X\right\}, \\
		& \beta_{(0,-1)}:=\max \left\{-x^2 \mid\left(x^1, x^2\right) \in X\right\} .
	\end{aligned}
\end{equation}
Theo công thức (\ref{ct2.2}) ta có:

\begin{center}
	$\beta_{(-1, 0)} \textless \beta_{(1, 0)}$ \text{ và } $\beta_{(0, -1)} \textless \beta_{(0, 1)}$
\end{center}
Vì vậy, ${P}^{outer}$ là một hình chữ nhật phù hợp với 4 đỉnh phân biệt, có tập đỉnh là:
\begin{align}\label{ct2.9}
	P := \{r_1, r_2, r_3, r_4\}
\end{align}
Trong đó:
\begin{equation}\label{ct2.10}
	\begin{aligned}
		& r_1:=\left(\beta_{(1,0)}, \beta_{(0,1)}\right), \\
		& r_2:=\left(\beta_{(-1,0)}, \beta_{(0,1)}\right), \\
		& r_3:=\left(\beta_{(-1,0)}, \beta_{(0,-1)}\right), \\
		& r_4:=\left(\beta_{(1,0)}, \beta_{(0,-1)}\right) .
	\end{aligned}
\end{equation}
Trong các bước xấp xỉ tiếp theo, việc xây dựng đa giác ${P}^{outer}$ lần lượt được cải thiện như sau:

$\text{Với 1 đỉnh }p \in P, \text{cho } p^{-} \in P \text{ và } p^{+} \in P \text{ lần lượt là}$
\begin{align} \label{ct2.11}
\text {điểm liền trước ngược chiều kim đồng hồ và điểm liền sau của} p \in P.
\end{align}. 


Ta có công thức sau:
\begin{equation}\label{def_d_p}
	\begin{array}{lcl}
		d_{p}^T &:=& \|p^+ - p^-\|^{-1}\, R \, (p^+ - p^-)^T, \\
		\beta_{d_{p}} &:=& \max\{d_{p}\, x^T \mid x \in X\},
	\end{array}
\end{equation}
trong đó:
\begin{equation}\label{rotationmatrix}
	R := \begin{pmatrix}
		0 & 1 \\
		-1 & 0
	\end{pmatrix}
\end{equation}
là ma trận xoay chiều theo hướng kim đồng hồ với góc xoay $\pi/2$. Vì $R$ là ma trận xoay, ta có:
\begin{equation}\label{def_d_p1}
	\|d_{p}\| = \|p^+ - p^-\|^{-1}\, \|(p^+ - p^-) R^T\| = \|p^+ - p^-\|^{-1}\, \|p^+ - p^-\| = 1.
\end{equation}
Sẽ có hai trường hợp xảy ra khi ta thêm các ràng buộc tuyến tính sau đây vào định nghĩa của ${P}^{outer}$ trong công thức (\ref{ct2.6}):
\begin{equation}\label{linearconstr}
	d_p\, x^T \leq \beta_{d_p}.
\end{equation}

Đầu tiên, nếu:
\begin{equation}\label{betaequal}
	\beta_{d_p} = d_p\, p^+
\end{equation}
thì công thức (\ref{def_d_p1}) không tạo thêm đỉnh mới nhưng sẽ thêm 2 cạnh mới  $[p^-, p^+]$ của ${\cal P}^{\rm outer}$. Cho  $d_{[p^-, p]}$ và $d_{[p, p^+]}$ biểu thị 2 hướng cực đại từ D, định nghĩa hai cạnh $[p^-, p]$ và $[ p, p^+]$ của ${\cal P}^{\rm outer}$. Sau đó $d_{[p^-, p]}$ and $d_{[p, p^+]}$ sẽ trở nên vô dụng. Vì vậy, trong khi thêm $d_p$ vào tập $D$ cần phải loại bỏ $d_{[p^-, p]}$ và $d_{[p, p^+]}$ và $p$ trong $P$, nghĩa là:
\begin{equation}\label{newDP2}
	\begin{array}{lcl}
		D &:=& (D \cup \{d_{p}\})\setminus \{d_{[p^-,p]}, d_{[p,p^+]}\}, \\
		P &:=& P \setminus \{p\}.
	\end{array}
\end{equation}
Thứ hai, nếu
\begin{equation}\label{betagreater}
	\beta_{d_p} > d_p\, p^+
\end{equation}
và:
\begin{equation}\label{greaterdelta}
	d_{p}\, p^T - \beta_{d_{p}} > \delta
\end{equation}
thì ràng buộc mới (\ref{linearconstr}) tạo ra hai đỉnh mới của ${\cal P}^{\rm outer}$ có tên $\hat p^-$ và $\hat p^+$ sẽ được tính như sau:
\begin{equation}\label{def_hatp}
	\begin{array}{lcl}
		\lambda_p &:=& (\beta_{d_p} - d_p\, p^{-T})/(d_p\, p^T - d_p\, p^{-T}) \in (0, 1), \\
		\hat p^- &:=& (1 - \lambda_p)\, p^{-T} + \lambda_p\, p^T, \\
		\hat p^+ &:=& (1 - \lambda_p)\, p^{+T} + \lambda_p\, p^T.
	\end{array}
\end{equation}













======================================================













Trong các thuật toán tìm bao lồi thì thuật toán Quickhull \cite{David-2002, Rourke-1998} được biết đến là một thuật toán hiệu quả có độ phức tạp tính toán trung bình là $O(n \log n)$ nhưng trong trường hợp xấu nhất thì độ phức tạp là $O(n^2)$, trong đó $n$ là số điểm của tập điểm đầu vào của thuật toán. Độ phức tạp của thuật toán Quickhull tương tự như thuật toán Quicksort - một thuật toán sắp xếp hiệu quả dựa trên việc phân chia mảng dữ liệu thành các nhóm phần tử nhỏ hơn và thuật toán này chạy trong thực tế nhanh hơn rất nhiều so với trường hợp xấu nhất. Để giải thích cho điều này, V. Damerow và C. Sohler đã đánh giá thành công số điểm cực biên của một tập hợp theo nghĩa Smoothed analysis \cite{Damerow-2004}. Từ đó có thể đánh giá độ phức tạp tính toán của thuật toán Quickhulll theo nghĩa này trong hai trường hợp là:
\begin{itemize}
	\item Nhiễu ngẫu nhiên của tập điểm được chọn từ phân bố chuẩn $N(0, \delta)$: 
	O$\left( n \left(\dfrac{1}{\delta} \right)^2 \log^2 n\right) $.
	\item Nhiễu ngẫu nhiên được chọn từ phân bố đều trong hình vuông kích thước $2 \epsilon$: 
	O$\left( n \left(\dfrac{n \log n}{\epsilon} \right)^{2/3}\right). $
\end{itemize}

Bài toán tìm bao lồi có ứng dụng rất quan trọng trong lĩnh vực nhận dạng. Các ứng dụng phổ biến của nhận dạng trong thực tế là nhận dạng tiếng nói tự động, phân loại văn bản thành nhiều loại khác nhau (ví dụ những thư điện tử spam/non-spam), nhận dạng tự động các mã bưu điện viết tay trên các bao thư, hay hệ thống nhận dạng mặt người, nhận dạng biển số xe, v.v\ldots Sau đây ta xét một ứng dụng cụ thể của bài toán tìm bao lồi trong nhận dạng biển số xe. 
\begin{figure}[ht!]
	\begin{center}
		\includegraphics[width=200px]{./nhandang1.PNG}
		\caption{Quy trình tự động nhận dạng biển số xe.}
		\label{fig_dhandang1}
	\end{center}
\end{figure} 

\section{Sơ lược về ............ }
\begin{dn}\rm {\it Phương trình đồng dư đại số bậc $n$} là một đồng dư thức có dạng
\begin{align} \label{ptdd}
f(x)= a_0x^n + a_1x^{n-1} + \ldots + a_n \equiv 0\pmod{m}
\end{align}
trong đó $x$ là ẩn, $a_i \in \mathbb{Z}$ (với $i = 1, 2, \ldots, n$) và $a_0\not\equiv 0\pmod m$.
\end{dn} 
\begin{cy}\rm (i) Giải phương trình (\ref{ptdd}) là tìm tất cả các giá trị nguyên của $x$ thoả mãn đồng dư thức (\ref{ptdd}). Nếu $x = x_0$ thoả mãn phương trình (\ref{ptdd}) thì mọi số $x \equiv x_0\pmod{m}$ đều thoả mãn (\ref{ptdd}); trong trường hợp này tập hợp $\{x\in\Z\mid x\equiv x_0\pmod m\}$ được gọi là một {\it nghiệm} của phương trình đồng dư (\ref{ptdd}), kí hiệu là $\overline{x_0}$ hoặc $x\equiv x_0\pmod m$.\par
\item (ii) Số nghiệm của phương trình (\ref{ptdd}) là số các phần tử trong một hệ thặng dư đầy đủ theo modulo $m$ mà thỏa mãn (\ref{ptdd}).\par
\item (iii) Hai phương trình đồng dư được gọi là tương đương nếu tập hợp các số nguyên thỏa mãn các phương trình đó là trùng nhau.
\end{cy}

\begin{vd} \rm Xét phương trình $x^2 \equiv 1 \pmod{5}$.
\end{vd}

\begin{giai} Ta thấy trong các số 0, 1, 2, 3, 4 của hệ thặng dư không âm bé nhất theo modulo 5, có hai số 1 và 4 thỏa mãn phương trình đã cho. Vậy phương trình có hai nghiệm là $x \equiv 1 \pmod{5}$ và $x \equiv 4 \pmod{5}$.
\end{giai}

\begin{vd} \rm Giải phương trình đồng dư $x^4 + 7x + 4 \equiv 0\pmod{9}$.
\end{vd}
\begin{giai} Dễ thấy phương trình $x^4 + 7x + 4 \equiv 0\pmod{3}$ có nghiệm là $x \equiv 1\pmod{3}$ (hay $x = 3t +1$ với $t\in\Z$). Thay $x$ vào phương trình cần giải và bỏ đi những số hạng chia hết cho 9 ta được
	\begin{align*}
	&6t + 3  \equiv 0\pmod{9}\\
	\Leftrightarrow \ & 2t + 1  \equiv 0\pmod{3}\\
	\Leftrightarrow \ & t \equiv 1\pmod{3}\\
		\Leftrightarrow \ & t = 3k +1.
	\end{align*}
Vậy phương trình có nghiệm là $x = 3(3k+1) + 1$ hay $x \equiv 4\pmod{9}$.
\end{giai}

 \begin{dn} \rm Phương trình đồng dư $ax \equiv b \pmod{m}$ được gọi là {\it phương trình đồng dư tuyến tính} với $a, b, m$ là các số nguyên đã biết. Khi đó $x\equiv x_0\pmod m$ là một nghiệm của phương trình khi và chỉ khi $ax_0 \equiv b\pmod{m}$.
\end{dn}





\chapter{Ứng dụng .................}

Chương này trình bày định nghĩa và các tính chất của thặng dư bậc hai: cách tính thặng dư bằng định nghĩa, cách tính thặng dư thông qua ký hiệu Legendre, cách tính thông qua luật thuận nghịch bậc hai. Sau đó ứng dụng thặng dư bậc hai và luật thuận nghịch bậc hai để tính toán và giải một số bài toán chứng minh, tìm căn nguyên thủy, kiểm tra tính nguyên tố.  

\section{Thặng dư bậc hai và ứng dụng}
Thặng dư bậc hai đóng vai trò rất quan trọng trong lý thuyết số. Chẳng hạn, thuật toán phân tích số nguyên ra thừa số nguyên tố. Ngoài ra thặng dư bậc hai cũng ứng dụng lớn trong mật mã cũng như trong các giao thức mã hóa.... Ở đây ta xét ứng dụng liên quan đến giải phương trình đồng dư bậc hai trong lý thuyết và thực hành.
 
\subsection{Phương trình đồng dư bậc hai..........}
Xét phương trình đồng dư bậc hai theo modulo nguyên tố (theo tài liệu \cite{K2007}).
\begin{align}\label{pt7.1}
Ax^2 + Bx + C \equiv 0 \pmod{p},
\end{align}
trong đó $p$ nguyên tố lẻ và $A, B, C \in \mathbb{Z}$ với $p\nmid A$. (Nếu $p\mid A$ thì quay về phương trình tuyến tính). Vì $p$ nguyên tố lẻ và $p\nmid A$, nên $p\nmid 4A$. Ta nhân hai vế của phương trình với $4A$ ta được
\begin{equation}\label{pt7.2}
4A(Ax^2+Bx+C)\equiv 0\pmod p.
\end{equation}
Nhưng ta có 
\begin{align*}
4A(Ax^2+Bx+C)&=4A^2x^2+4ABx+4AC\\
&=(2Ax+B)^2-(B^2-4AC).
\end{align*}
Do đó đồng dư thức (\ref{pt7.2}) được viết lại thành
\begin{align*}
(2Ax+B)^2\equiv (B^2-4AC)\pmod p
\end{align*}
nó có dạng 
\begin{align}\label{pt7.3}
y^2\equiv a\pmod p
\end{align}
 trong đó $y=2Ax+B$ và $a=B^2-4AC$.\par 
Nếu phương trình $y^2\equiv a\pmod p$ có nghiệm, thì ta suy ra phương trình $2Ax+B=y$ có nghiệm $x$ modulo $p$ (vì $(2A,p)=1$). Do đó phương trình (\ref{pt7.1}) có nghiệm nếu và chỉ nếu phương trình (\ref{pt7.3}) có nghiệm.\par

Ví dụ sau sẽ minh họa điều này.

	{\fontsize{12pt}{12pt}\selectfont \baselineskip 0.65cm
	\renewcommand{\baselinestretch}{1.0}	
	\begin{algorithm}[ht!]
		
		\floatname{algorithm}{Thuật toán}
		\caption{\textsc{Thuật toán tìm bao lồi dưới} $\hbox{conv}_L(P)$}  \label{al-blduoi}
		\textbf{Đầu vào: }Cho $P=\{p_i=(x_i,y_i,z_i)\in \mathbb{R}^3,\ i=1,\dots,n\}, n\ge 3$.\\
		\textbf{Đầu ra:} Tập ${\cal Q}$ tất cả các mặt dưới của $\hbox{conv}_L(P)$.
		
		\begin{algorithmic}[1]
			
			
			\State Tìm cạnh đầu tiên $e_0$ của $\hbox{conv}_L(P)$. 
			\State Xét hàng đợi ${\cal Q}:=\emptyset$ và tập ${\cal E}_L(P):=\emptyset$.
			
			\State Gọi {\bf LFRes}($e, P$) để nhận được một mặt dưới $F_e$ qua $e_0$. Đẩy các cạnh của $F_e$  trừ $e_0$ vào trong ${\cal E}_L(P)$. Đẩy $F_e$ vào trong tập ${\cal Q}$.
			
			\State  {\bf while} $({\cal Q}\ne\emptyset)$ {\bf do}
			
			\State 
			\quad \quad Lấy $F_e$ từ phía trên của  ${\cal Q}$.
			
			\State 	\quad \quad \quad \quad $T:=$ tập các cạnh $F_e$.
			
			\State 	\quad \quad \quad \quad {\bf for each} $e \in T\cap  {\cal E}_L(P)$ {\bf do}
			
			\State 
			\quad \quad\quad \quad\quad \quad Gọi {\bf LFRes}($e, P$) để nhận được mặt $F'_e$ có chung cạnh $e$ với $F_e$. \hspace*{2.5cm}Đưa vào ${\cal E}_L(P)$ tất cả các cạnh $e' \ne e_0$ của $F'_e$ chưa xuất hiện trong \hspace*{2.5cm} ${\cal E}_L(P)$ và xoá các cạnh đã xuất hiện trong ${\cal E}_L(P)$. Đẩy $F'_e$ vào ${\cal Q}$.
		
			
		\end{algorithmic}
	\end{algorithm}
}

	\chapter{Một số kết quả tính toán }
Trong nội dung này chúng tôi thử nghiệm số cho thuật toán trong \cite{An-Giang} và thuật toán vừa được trình bày ở mục trước để so sánh tốc độ của chúng. Các thuật toán này được thực thi bởi chương trình C và chạy trên PC Core i5 1.6 GHz 3M với 4 GB RAM.  

Dưới đây Bảng \ref{tab:51} minh họa thời gian chạy (đơn vị tính bằng giây) của thuật toán tính bao lồi dưới được giới thiệu bởi P. T. An và D. T. Giang trong \cite{An-Giang} và Thuật toán \ref{al-matduoi} sử dụng kỹ thuật hạn chế của chúng tôi. Cột cuối cùng liệt kê tỉ lệ tăng tốc của thuật toán của chúng tôi so với thuật toán trong \cite{An-Giang}. Dữ liệu đầu vào của các thuật toán là các tập điểm được tạo trên bề mặt một paraboloid (tất cả các điểm đều là đỉnh của bao lồi và bao lồi dưới) có dạng $P = \{p_i = (x_i, y_i, z_i): x_i, y_i, z_i \in \mathbb{R}, z_i = x_i^2 + y_i^2, i = 1, \ldots, n\} \subset \mathbb{R}^3,$ trong đó tập $\{(x_i, y_i), x_i, y_i \in R, i = 1, \ldots , n \}$ được chọn ngẫu nhiên từ phân bố đều trong hình vuông cỡ 200 $\times$ 200. 

{\fontsize{12pt}{12pt}\selectfont \baselineskip 0.65cm
	\renewcommand{\baselinestretch}{1}
	\begin{table}[ht!]
		\begin{center}
			\caption{Thời gian chạy tính bao lồi dưới (đơn vị: giây).}
			\label{tab:51}
			\begin{tabular}{cccc}
				\hline
				{Đầu vào} &{Thuật toán trong} \cite{An-Giang} & {Thuật toán} \ref{al-blduoi}& Tỉ số thăng tốc\\
				\hline
				1.000 & 0,136& 0,061&2,23\\ 
				2.000 & 0,454& 0,248 &1,83\\  
				5.000 & 2,684& 1,500 &1,79\\  
				7.000 & 7,014& 3,129 &2,24\\ 
				11.000  & 14,321& 8,484 &1,69\\ 
				17.000  & 41,307& 24,666 &1,67\\ 
				20.000 & 63,197& 37,332 &1,69\\  
				22.000 & 70,866& 40,235 & 1,76\\ 
				30.000 & 153,240& 96,738 &1,58\\ 
				35.000& 200,496& 125,490& 1,60\\ \hline	
			\end{tabular}	
		\end{center}
	\end{table}	
}







\chapter*{{Kết luận}}
\addcontentsline{toc}{chapter}{\vspace*{-8pt} Kết luận}

 Trong quá trình thực tập, em đã có cơ hội làm quen một môi trường làm việc mới. Em đã tính lũy những kinh nghiệm về kiến thức trong công việc cũng như các kinh nghiệm về kỹ năng mềm.
 
 Em được rèn luyện kĩ năng giải quyết công việc theo từng giai đoạn, cố gắng hoàn thành công việc trong thời gian cho phép, mạnh dạn trao đổi và chia sẻ kiến thức. Đồng thời cũng bồi dưỡng thêm rất nhiều kiến thức ngoài các kiến thức đã học trên trường.
 




\begin{thebibliography}{30}
\addcontentsline{toc}{chapter}{\vspace*{-8pt} Tài liệu tham khảo}
	
\subsection*{Tiếng Việt}

\bibitem{G2016} Vũ Thị Gái (2016), \textit{Luật thuận nghịch bậc hai và điểm nguyên}, trường Đại học Khoa học, Đại học Thái Nguyên.

\bibitem{D2005} Nguyễn Tiến Hùng (2016), \textit{Luật thuận nghịch bậc hai và hoán vị}, trường Đại học Khoa học, Đại học Thái Nguyên.


\bibitem{K1997} Hà Huy Khoái (1997), \textit{Nhập môn số học thuật toán}, Nhà xuất bản Khoa học Kỹ thuật.

\bibitem{LDT} Lại Đức Thịnh (1977), {\it Giáo trình số học}, Nhà xuất bản Giáo dục.
	
\subsection*{Tiếng Anh}
	\bibitem{An-Giang} P. T. An and D. T. Giang (2015), ``A direct method for determining the lower convex hull of a finite point set in 3D'', Advances in Intelligent Systems and Computing, \textit{Springer}, Proceedings of 3rd International Conference on Computer Science, Applied Mathematics and Applications (ICCSAMA, May 11-13, Metz, France) \textbf{358},  pp. 15--26.


\bibitem{Damerow-2004} V. Damerow and C. Sohler (2004), ``Extreme points under random noise'', \textit{Eropean Symposium on Algorithms} {\bf 3221}, pp. 264--274.
\bibitem{David-2002}  M. M. David (2002), \textit{Computation geometry}, Department of Computer Science.

\bibitem{Rourke-1998} J. O' Rourke (1998), \textit{Computational geometry in C}, 2nd edition, Cambridge University Press, Cambridge. 
	
\end{thebibliography} 
\end{document}
 
